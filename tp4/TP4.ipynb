{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "55339855-cf14-4697-a122-4b54a92c6f6b",
      "metadata": {
        "id": "55339855-cf14-4697-a122-4b54a92c6f6b"
      },
      "source": [
        "# TP4 : model-free RL \n",
        "\n",
        "Jusqu'à lors, nous avons étudié des cas où le modèle de la matrice de transition et de la récompense étaient modélisés : c'est le cadre du *model-based reinforcement learning*. \n",
        "Pour gérer des cas plus complexes, nous devons soulager ces hypothèses. Dans le *model-free reinforcement learning*, on regarde les expériences passées, échecs comme réussites, pour simuler le modèle sous-jacent.\n",
        "\n",
        "Ce TP propose d'implémenter plusieurs algorithmes allant dans ce sens.\n",
        "\n",
        "\n",
        "RAPPEL : 1/4 de la note finale est liée à la mise en forme : \n",
        "\n",
        "* pensez à nettoyer les outputs inutiles (installation, messages de débuggage, ...)\n",
        "* soignez vos figures : les axes sont-ils faciles à comprendre ? L'échelle est adaptée ? \n",
        "* commentez vos résultats : vous attendiez-vous à les avoir ? Est-ce étonnant ? Faites le lien avec la théorie.\n",
        "\n",
        "Ce TP reprend l'exemple d'un médecin et de ses vaccins. Vous allez comparer plusieurs stratégies et trouver celle optimale.\n",
        "Un TP se fait en groupe de 2 à 4. Aucun groupe de plus de 4 personnes. \n",
        "\n",
        "Vous allez rendre le TP dans une archive ZIP. L'archive ZIP contient ce notebook au format `ipynb`, mais aussi exporté en PDF & HTML. \n",
        "L'archive ZIP doit aussi contenir un fichier txt appelé `groupe.txt` sous le format:\n",
        "\n",
        "```\n",
        "Nom1, Prenom1, Email1, NumEtudiant1\n",
        "Nom2, Prenom2, Email2, NumEtudiant2\n",
        "Nom3, Prenom3, Email3, NumEtudiant3\n",
        "Nom4, Prenom4, Email4, NumEtudiant4\n",
        "```\n",
        "\n",
        "Un script vient extraire vos réponses : ne changez pas l'ordre des cellules et soyez sûrs que les graphes sont bien présents dans la version notebook soumise. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e82f9115-21f6-4931-8920-e3be1555e289",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e82f9115-21f6-4931-8920-e3be1555e289",
        "outputId": "426c4517-0762-4188-e6bb-9f77dd89e031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n",
            "Requirement already satisfied: gym[classic_control,toy_text] in /usr/local/lib/python3.8/dist-packages (0.25.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym[classic_control,toy_text]) (1.5.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym[classic_control,toy_text]) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym[classic_control,toy_text]) (4.13.0)\n",
            "Requirement already satisfied: pygame==2.1.0 in /usr/local/lib/python3.8/dist-packages (from gym[classic_control,toy_text]) (2.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym[classic_control,toy_text]) (3.11.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install numpy matplotlib 'gym[toy_text, classic_control]'\n",
        "# Pour gérer les dépendances de PyGame: https://www.pygame.org/wiki/Compilation\n",
        "# A cause de PyGame, la version de Python doit être inférieure à 3.10 !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8ede7081-b933-476b-9d38-87d752a87777",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ede7081-b933-476b-9d38-87d752a87777",
        "outputId": "940a32f0-3798-4642-b42f-5e0c405f92ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import random\n",
        "#XVFB will be launched if you run on a server\n",
        "import os\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
        "    !bash ../xvfb start\n",
        "    %env DISPLAY=:1\n",
        "    \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import clear_output\n",
        "import gym\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "659ea33d-04c0-401e-af52-f972be093985",
      "metadata": {
        "id": "659ea33d-04c0-401e-af52-f972be093985"
      },
      "source": [
        "## Présentation de Gym\n",
        "Dans ce TP, nous allons le simulateur Gym par Open AI. Gym fournit une série d'environnements qui ont permis aux chercheurs de se comparer et ainsi, de faire accélérer la recherche en reinforcement learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2bbfe25c-6c12-46ac-9c54-6229d5ba8bdd",
      "metadata": {
        "id": "2bbfe25c-6c12-46ac-9c54-6229d5ba8bdd"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"Taxi-v3\", render_mode=\"rgb_array\")\n",
        "\n",
        "env.reset()\n",
        "for _ in range(10):\n",
        "    env.render()\n",
        "    env.step(env.action_space.sample()) # Take a random action\n",
        "    \n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db5b0202-7a52-4648-87fa-dfccd1d6e179",
      "metadata": {
        "id": "db5b0202-7a52-4648-87fa-dfccd1d6e179"
      },
      "source": [
        "**Q1. Décrire l'environnement Taxi. En particulier, vous vous demanderez quel est l'espace d'action ? Des états ? Comment est définie la récompense ? Que contient l'output de `env.step` ?**\n",
        "\n",
        "La documentation de cet environnement est disponible ici:\n",
        "    [https://www.gymlibrary.dev/api/core/#gym.Env.step](https://www.gymlibrary.dev/api/core/#gym.Env.step)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1208b78d-bbcb-4023-95db-4622e47bca86",
      "metadata": {
        "id": "1208b78d-bbcb-4023-95db-4622e47bca86"
      },
      "source": [
        "# Il y a 6 actions déterministe:\n",
        "0: déplacement sud\n",
        "\n",
        "1: déplacement Nord\n",
        "\n",
        "2: déplacement Est\n",
        "\n",
        "3: déplacement Ouest\n",
        "\n",
        "4: Récupérer un passager\n",
        "\n",
        "5: Déposer un passager\n",
        "\n",
        "# Rewards\n",
        "-1 par itération sauf s'il y a une nouvelle récompense.\n",
        "\n",
        "+20 pour déposer un passager.\n",
        "\n",
        "-10 Récupérer et déposer illégalement un passager."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90446e1c-0cd7-423e-b887-591cd39ee473",
      "metadata": {
        "id": "90446e1c-0cd7-423e-b887-591cd39ee473"
      },
      "source": [
        "## Q-Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8172a4c1-1fac-4cc0-ad4f-eaf34ff6c070",
      "metadata": {
        "id": "8172a4c1-1fac-4cc0-ad4f-eaf34ff6c070"
      },
      "source": [
        "Dans cette partie, nous allons utiliser le Q-Learning pour résoudre cette tâche."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7cb761a5-c886-45d4-96c6-1c8b86037773",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "7cb761a5-c886-45d4-96c6-1c8b86037773",
        "outputId": "7f906324-8e95-4247-d431-4dd86648e7b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean reward -200.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from qlearning import QLearningAgent\n",
        "\n",
        "env = gym.make(\"Taxi-v3\", render_mode=\"rgb_array\")\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "agent = QLearningAgent(\n",
        "    learning_rate=0.5,\n",
        "    epsilon=0.25,\n",
        "    gamma=0.99,\n",
        "    legal_actions=list(range(n_actions))\n",
        ")\n",
        "\n",
        "def play_and_train(env: gym.core.Env, agent: QLearningAgent, t_max=int(1e4)) -> float:\n",
        "    \"\"\"\n",
        "    This function should \n",
        "    - run a full game, actions given by agent.getAction(s)\n",
        "    - train agent using agent.update(...) whenever possible\n",
        "    - return total rewardb\n",
        "    \"\"\"\n",
        "    total_reward = 0.0\n",
        "    s, info = env.reset(return_info = True)\n",
        "    \n",
        "    for t in range(t_max):\n",
        "        # TODO get agent to pick action given state s\n",
        "        agent_action = agent.get_action(s)\n",
        "\n",
        "        a = 0\n",
        "        \n",
        "        next_s, r, done, truncated= env.step(a)\n",
        "        \n",
        "        # TODO train agent for state s\n",
        "        agent.update(s, agent_action, next_s, r)\n",
        "        \n",
        "        s = next_s\n",
        "        total_reward +=r\n",
        "        if done:\n",
        "            break\n",
        "        \n",
        "    return total_reward\n",
        "\n",
        "rewards = []\n",
        "for i in range(1000):\n",
        "    rewards.append(play_and_train(env,agent))    \n",
        "    if i % 100 ==0:\n",
        "        clear_output(True)\n",
        "        print(\"mean reward\",np.mean(rewards[-100:]))\n",
        "        plt.plot(rewards)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f88b6f0e-2615-475c-ad5b-6617222e5842",
      "metadata": {
        "id": "f88b6f0e-2615-475c-ad5b-6617222e5842"
      },
      "source": [
        "**Q2. Complétez les bouts manquants de code dans `qlearning.py` et dans la fonction `play_and_train`. Entrainez l'agent. Que se passe-t'il ? Regardez des exemples de trajectoire.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36f217a9-0824-48dd-933d-5adf7e27b1c7",
      "metadata": {
        "id": "36f217a9-0824-48dd-933d-5adf7e27b1c7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "48490cf6-0dc5-4f03-a354-7e54058ca0a4",
      "metadata": {
        "id": "48490cf6-0dc5-4f03-a354-7e54058ca0a4"
      },
      "source": [
        "## Réduire epsilon au-fur-et-à-mesure\n",
        "\n",
        "Pour améliorer les performances, nous allons réduire $\\epsilon$ au cours du temps.\n",
        "\n",
        "La manière la plus simple consiste à réduire $\\epsilon$ à chaque épisode, par exemple en le multipliant par un nombre proche de 1 (tel que 0.99) ou lui soustraire un pettit nombre. Vous pouvez, bien sûr, envisager d'autres stratégies !\n",
        "\n",
        "**Q3. Améliorez l'algorithme dans `q_learning_eps_scheduling.py` de sorte à avoir une récompense positive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d3dd6baf-a206-47bd-b978-f3e9cd59fde6",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "d3dd6baf-a206-47bd-b978-f3e9cd59fde6",
        "outputId": "379aed01-e435-49a8-d95b-98f86c1d7b29"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-0dba6541f6e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplay_and_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-209e4e0536e3>\u001b[0m in \u001b[0;36mplay_and_train\u001b[0;34m(env, agent, t_max)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# TODO train agent for state s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/qlearning.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, state, action, reward, next_state)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# TODO: compute the Q-value update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mTD_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mQ_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mTD_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTD_target\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mQ_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mQ_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ_old\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mTD_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/qlearning.py\u001b[0m in \u001b[0;36mget_qvalue\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \"\"\"\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_qvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
          ]
        }
      ],
      "source": [
        "from qlearning_eps_scheduling import QLearningAgentEpsScheduling\n",
        "\n",
        "agent = QLearningAgentEpsScheduling(\n",
        "    learning_rate=0.5,\n",
        "    epsilon=0.25,\n",
        "    gamma=0.99,\n",
        "    legal_actions=list(range(n_actions))\n",
        ")\n",
        "\n",
        "rewards = []\n",
        "for i in range(1000):\n",
        "    rewards.append(play_and_train(env,agent))    \n",
        "    if i %100 ==0:\n",
        "        clear_output(True)\n",
        "        print(\"mean reward\",np.mean(rewards[-100:]))\n",
        "        plt.plot(rewards)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe545baf-9a53-47cc-8d47-18a886b933f4",
      "metadata": {
        "id": "fe545baf-9a53-47cc-8d47-18a886b933f4"
      },
      "source": [
        "*[Ajoutez votre réponse ici]*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7106d2e-55c6-4ffa-a732-a32e12159dce",
      "metadata": {
        "id": "e7106d2e-55c6-4ffa-a732-a32e12159dce"
      },
      "source": [
        "**Q4. Produisez quelques vidéos des trajectoires obtenus. Rassemblez des cas de réussite et des cas d'échecs**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6cbe8e3-1790-441d-8b43-57f18df41e4d",
      "metadata": {
        "id": "d6cbe8e3-1790-441d-8b43-57f18df41e4d"
      },
      "source": [
        "## Espace d'action continu\n",
        "\n",
        "Nous allons maintenant passer à un environnement plus difficile : le pendule inversé. C'est un grand classique des problèmes de contrôle !\n",
        "\n",
        "Puisque l'environnement a un espace d'actions continu, nous allons discrétiser cet espace pour revenir aux cas précédemment étudiés.\n",
        "La solution la plus simple pour cela consiste à diviser l'espace en sections égales. Mais comment choisir le nombre de sections ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "4570b6ee-297a-4136-ab66-59adb3f2dab9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "4570b6ee-297a-4136-ab66-59adb3f2dab9",
        "outputId": "79a59b4c-5cc3-4c80-d29d-21137b58765e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first state:  [ 0.00431092 -0.04906922 -0.01831933 -0.01529009]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f54ada9cc10>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(\"first state: \", env.reset())\n",
        "plt.imshow(env.render()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc5417ec-eb7e-48fb-aa0c-6bbc8fd5b436",
      "metadata": {
        "id": "fc5417ec-eb7e-48fb-aa0c-6bbc8fd5b436"
      },
      "source": [
        "**Q5. Décrivez cet environnement à l'aide de la documentation de Gym en reprenant la Q1.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d67baed-4bfc-4a59-a76a-dbbc19cbbd2c",
      "metadata": {
        "id": "2d67baed-4bfc-4a59-a76a-dbbc19cbbd2c"
      },
      "source": [
        "*Va dé rétro satanas*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3514cb53-9981-4fd5-8f7d-652de722c0a3",
      "metadata": {
        "id": "3514cb53-9981-4fd5-8f7d-652de722c0a3"
      },
      "source": [
        "Pour mener à bien notre discrétisation de l'espace des actions, nous allons estimer la distribution des observations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cdee467-d593-4be0-85b5-20c11b2725d0",
      "metadata": {
        "id": "8cdee467-d593-4be0-85b5-20c11b2725d0"
      },
      "source": [
        "**Q6. Simulez 1000 épisodes et regardez la distribution des états à l'aide d'un histogramme. Quel paramètre vous paraît optimal pour choisir le nombre de `bins` ?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "89ac1824-18e8-419f-9e47-cea3926512bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "89ac1824-18e8-419f-9e47-cea3926512bd",
        "outputId": "74feddd4-badd-4c0d-d8b8-1cfd3a072d6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Pole Angular Velocity')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "env.action_space.seed(42)\n",
        "\n",
        "observation, info = env.reset(seed=42, return_info=True)\n",
        "Observ = []\n",
        "\n",
        "for _ in range(1000):\n",
        "    observation, reward, terminated, truncated = env.step(env.action_space.sample())\n",
        "\n",
        "    if terminated or truncated:\n",
        "        observation, info = env.reset(return_info=True)\n",
        "    Observ.append(observation)\n",
        "\n",
        "fig, axs = plt.subplots(2, 2)\n",
        "axs[0,0].hist([elem[0] for elem in Observ], bins=50)\n",
        "axs[0,0].set_title(\"Cart Position\")\n",
        "axs[0,1].hist([elem[1] for elem in Observ], bins=50)\n",
        "axs[0,1].set_title(\"Cart Velocity\")\n",
        "axs[1,0].hist([elem[2] for elem in Observ], bins=50)\n",
        "axs[1,0].set_title(\"Pole Angle\")\n",
        "axs[1,1].hist([elem[3] for elem in Observ], bins=50)\n",
        "axs[1,1].set_title(\"Pole Angular Velocity\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a231538-b6a3-4420-9b73-965d958c8d74",
      "metadata": {
        "id": "0a231538-b6a3-4420-9b73-965d958c8d74"
      },
      "source": [
        "*On observe une distribution Binomiale des différents paramètres*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ff90a63-5b02-4055-bdca-7a6a9c8eb1aa",
      "metadata": {
        "id": "6ff90a63-5b02-4055-bdca-7a6a9c8eb1aa"
      },
      "source": [
        "## Discrétiser l'environnement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eef258ed-07aa-452a-94f8-dcce941915a9",
      "metadata": {
        "tags": [],
        "id": "eef258ed-07aa-452a-94f8-dcce941915a9"
      },
      "outputs": [],
      "source": [
        "from gym.core import ObservationWrapper\n",
        "\n",
        "def _discretize_range(lower_bound, upper_bound, num_bins):\n",
        "    return np.linspace(lower_bound, upper_bound, num_bins + 1)[1:-1]\n",
        "\n",
        "class Binarizer(ObservationWrapper):\n",
        "    def _observation(self, state: np.ndarray) -> np.ndarray:  \n",
        "        # TODO binarize each dimension of the state\n",
        "        num_discretization_bins = 7\n",
        "        self._state_bins = [\n",
        "            # Cart position.\n",
        "            self._discretize_range(-2.4, 2.4, num_discretization_bins),\n",
        "            # Cart velocity.\n",
        "            self._discretize_range(-3.0, 3.0, num_discretization_bins),\n",
        "            # Pole angle.\n",
        "            self._discretize_range(-0.5, 0.5, num_discretization_bins),\n",
        "            # Tip velocity.\n",
        "            self._discretize_range(-2.0, 2.0, num_discretization_bins)\n",
        "        ]\n",
        "        \n",
        "        return state\n",
        "    \n",
        "bi_env = Binarizer(gym.make(\"CartPole-v0\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "211e08b3-ca10-4377-9d86-2571439f5cbb",
      "metadata": {
        "id": "211e08b3-ca10-4377-9d86-2571439f5cbb"
      },
      "source": [
        "**Q7. Complétez le code ci-dessus pour binariser l'environnement. Regardez la nouvelle distribution des états. Qu'en pensez-vous ?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fca4be48-f1d8-4eab-a271-957c8b45d4db",
      "metadata": {
        "id": "fca4be48-f1d8-4eab-a271-957c8b45d4db"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "598a8ca4-d6b4-407c-8cfc-c870732fbb4a",
      "metadata": {
        "id": "598a8ca4-d6b4-407c-8cfc-c870732fbb4a"
      },
      "source": [
        "*[Ajoutez votre réponse ici]*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02d1b63f-465a-4006-96c3-35d8e921c25e",
      "metadata": {
        "id": "02d1b63f-465a-4006-96c3-35d8e921c25e"
      },
      "source": [
        "### Apprentissage sur l'environnement discretisé"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9944bf8-830c-4645-9df6-3fd471360b2e",
      "metadata": {
        "id": "d9944bf8-830c-4645-9df6-3fd471360b2e"
      },
      "source": [
        "**Q8. Reprenez votre agent pour résoudre cette tâche. Tracez la récompense et observez quelques trajectoires d'échecs et de réussites à l'aide de vidéos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0da18223-f328-48f3-9643-e1c9dba17ba8",
      "metadata": {
        "id": "0da18223-f328-48f3-9643-e1c9dba17ba8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d0627c3b-2f9b-434b-9f14-3e30615749e5",
      "metadata": {
        "id": "d0627c3b-2f9b-434b-9f14-3e30615749e5"
      },
      "source": [
        "*[Ajoutez votre réponse ici]*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56af0361-953c-4a03-8e7c-49840c2c9426",
      "metadata": {
        "id": "56af0361-953c-4a03-8e7c-49840c2c9426"
      },
      "source": [
        "## 4. Experience replay \n",
        "\n",
        "Les algorithmes *off-policy* peuvent s'entraîner grâce à des trajectoires anciennement obtenues. Tirons parti de cette propriété pour \n",
        "améliorer l'efficacité de nos algorithmes et les permettre de converger plus rapidement.\n",
        "\n",
        "L'idée générale est de collecter les tuplets `<s,a,r,s'>` dans un *buffer*, puis de mettre à jour la fonction Q sur l'ensemble de ces tuplets.\n",
        "Plus en détails, voici l'algorithme à suivre\n",
        "\n",
        "#### S'entraîner avec un *experience replay*\n",
        "1. Echantillonner un tuplet `<s,a,r,s'>`.\n",
        "2. Stocker ce tuplet dans un buffer FIFO : si le buffer est plein, on supprimer les données arrivées en premier.\n",
        "3. Choisir aléatoirement K tuplets du buffer et mettre à jour la fonction Q sur ces tuplets.\n",
        "\n",
        "**Q9. Implémentez un tel buffer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef979349-b4eb-4d4a-9a5b-4575a0e04d81",
      "metadata": {
        "tags": [],
        "id": "ef979349-b4eb-4d4a-9a5b-4575a0e04d81"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer(object):\n",
        "    def __init__(self, size):\n",
        "        \"\"\"\n",
        "        Create Replay buffer.\n",
        "        Parameters\n",
        "        ----------\n",
        "        size: int\n",
        "            Max number of transitions to store in the buffer. When the buffer\n",
        "            overflows the old memories are dropped.\n",
        "            \n",
        "        Note: for this assignment you can pick any data structure you want.\n",
        "              If you want to keep it simple, you can store a list of tuples of (s, a, r, s') in self._storage\n",
        "              However you may find out there are faster and/or more memory-efficient ways to do so.\n",
        "        \"\"\"\n",
        "       \n",
        "\n",
        "# Some tests to make sure your buffer works right\n",
        "\n",
        "replay = ReplayBuffer(2)\n",
        "obj1 = tuple(range(5))\n",
        "obj2 = tuple(range(5, 10))\n",
        "replay.add(*obj1)\n",
        "assert replay.sample(1) == obj1, \"If there's just one object in buffer, it must be retrieved by buf.sample(1)\"\n",
        "replay.add(*obj2)\n",
        "assert len(replay._storage) == 2, \"Please make sure __len__ methods works as intended.\"\n",
        "replay.add(*obj2)\n",
        "assert len(replay._storage) == 2, \"When buffer is at max capacity, replace objects instead of adding new ones.\"\n",
        "assert tuple(np.unique(a) for a in replay.sample(100)) == obj2\n",
        "replay.add(*obj1)\n",
        "assert max(len(np.unique(a)) for a in replay.sample(100)) == 2\n",
        "replay.add(*obj1)\n",
        "assert tuple(np.unique(a) for a in replay.sample(100)) == obj1\n",
        "print(\"Success!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce711801-4660-44f1-8189-cd91187bf5f0",
      "metadata": {
        "id": "ce711801-4660-44f1-8189-cd91187bf5f0"
      },
      "source": [
        "Maintenant utilisons ce replay buffer pour améliorer les performances d'entraînement.\n",
        "\n",
        "**Q10. Entraînez un agent avec le replay buffer. Comparez l'évolution de la récompense sur l'environnement Taxi avec un algorithme n'utilisant pas le replay buffer.**\n",
        "\n",
        "Pour rendre l'affichage plus visible, vous filterez la récompense avec un filtre de votre choix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d34cece-905d-4597-ae71-903c68f11296",
      "metadata": {
        "tags": [],
        "id": "7d34cece-905d-4597-ae71-903c68f11296"
      },
      "outputs": [],
      "source": [
        "agent_baseline = QLearningAgentEpsScheduling(\n",
        "    learning_rate=0.5,\n",
        "    epsilon=0.25,\n",
        "    gamma=0.99,\n",
        "    legal_actions=list(range(n_actions))\n",
        ")\n",
        "\n",
        "agent_replay = QLearningAgentEpsScheduling(\n",
        "    learning_rate=0.5,\n",
        "    epsilon=0.25,\n",
        "    gamma=0.99,\n",
        "    legal_actions=list(range(n_actions))\n",
        ")\n",
        "\n",
        "replay = ReplayBuffer(10000)\n",
        "\n",
        "def play_and_train(\n",
        "    env: gym.core.Env, \n",
        "    agent: QLearningAgent, \n",
        "    t_max: int = int(1e4),\n",
        "    batch_size: int = 32\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    This function should \n",
        "    - run a full game, actions given by agent.getAction(s)\n",
        "    - train agent using agent.update(...) whenever possible\n",
        "    - return total rewardb\n",
        "    \"\"\"\n",
        "    total_reward = 0.0\n",
        "    s, info = env.reset()\n",
        "    \n",
        "    for t in range(t_max):\n",
        "        # TODO get agent to pick action given state s\n",
        "        a = 0\n",
        "        \n",
        "        next_s, r, done, truncated, info = env.step(a)\n",
        "        \n",
        "        # TODO train agent for state s\n",
        "        # ...\n",
        "        if replay is not None:\n",
        "            # TODO update this part\n",
        "            pass\n",
        "        \n",
        "        s = next_s\n",
        "        total_reward +=r\n",
        "        if done:\n",
        "            break\n",
        "        \n",
        "    return total_reward"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63da335a-8376-44c1-8ac4-da691cad9b6b",
      "metadata": {
        "id": "63da335a-8376-44c1-8ac4-da691cad9b6b"
      },
      "source": [
        "*[Ajoutez votre réponse ici]*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}